{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb87b440-17d4-4cd8-9410-aff0e676cffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmci_evaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     regression_metrics,\n\u001b[1;32m     11\u001b[0m     classification_metrics,\n\u001b[1;32m     12\u001b[0m     evaluate_strategy,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_regression_models\u001b[39m(X_train, y_train, X_val, y_val, X_test, y_test):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit baselines, Ridge, GB; return metrics, strategy stats, and predictions.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# src/models/smci_models.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from src.evaluation.smci_evaluation import (\n",
    "    regression_metrics,\n",
    "    classification_metrics,\n",
    "    evaluate_strategy,\n",
    ")\n",
    "\n",
    "\n",
    "def run_regression_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Fit baselines, Ridge, GB; return metrics, strategy stats, and predictions.\"\"\"\n",
    "\n",
    "    results = {}\n",
    "    strategies = {}\n",
    "    preds = {}\n",
    "\n",
    "    # Naive zero\n",
    "    y_val_naive = np.zeros_like(y_val)\n",
    "    y_test_naive = np.zeros_like(y_test)\n",
    "    results[\"naive_zero\"] = regression_metrics(y_test, y_test_naive)\n",
    "    strategies[\"naive_zero\"] = evaluate_strategy(y_test, y_test_naive)\n",
    "    preds[\"naive_zero\"] = y_test_naive\n",
    "\n",
    "    # Constant-mean\n",
    "    const_mean = y_train.mean()\n",
    "    y_val_const = np.full_like(y_val, const_mean)\n",
    "    y_test_const = np.full_like(y_test, const_mean)\n",
    "    results[\"const_mean\"] = regression_metrics(y_test, y_test_const)\n",
    "    strategies[\"const_mean\"] = evaluate_strategy(y_test, y_test_const)\n",
    "    preds[\"const_mean\"] = y_test_const\n",
    "\n",
    "    # Ridge with val-based alpha tuning\n",
    "    alphas = np.logspace(-4, 2, 13)\n",
    "    best_alpha = None\n",
    "    best_val_rmse = np.inf\n",
    "\n",
    "    for alpha in alphas:\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"ridge\", Ridge(alpha=alpha)),\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        m_val = regression_metrics(y_val, y_val_pred)\n",
    "        if m_val[\"RMSE\"] < best_val_rmse:\n",
    "            best_val_rmse = m_val[\"RMSE\"]\n",
    "            best_alpha = alpha\n",
    "\n",
    "    X_trainval = np.vstack([X_train, X_val])\n",
    "    y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "    ridge_best = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(alpha=best_alpha)),\n",
    "    ])\n",
    "    ridge_best.fit(X_trainval, y_trainval)\n",
    "    y_test_ridge = ridge_best.predict(X_test)\n",
    "\n",
    "    results[\"ridge\"] = regression_metrics(y_test, y_test_ridge)\n",
    "    strategies[\"ridge\"] = evaluate_strategy(y_test, y_test_ridge)\n",
    "    preds[\"ridge\"] = y_test_ridge\n",
    "\n",
    "    # Gradient Boosting with small manual grid\n",
    "    param_grid = [\n",
    "        {\"n_estimators\": 200, \"max_depth\": 2, \"learning_rate\": 0.05},\n",
    "        {\"n_estimators\": 300, \"max_depth\": 2, \"learning_rate\": 0.05},\n",
    "        {\"n_estimators\": 300, \"max_depth\": 3, \"learning_rate\": 0.05},\n",
    "        {\"n_estimators\": 300, \"max_depth\": 3, \"learning_rate\": 0.03},\n",
    "    ]\n",
    "\n",
    "    best_params = None\n",
    "    best_val_rmse = np.inf\n",
    "\n",
    "    for params in param_grid:\n",
    "        gb = GradientBoostingRegressor(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            random_state=0,\n",
    "        )\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_val_pred = gb.predict(X_val)\n",
    "        m_val = regression_metrics(y_val, y_val_pred)\n",
    "        if m_val[\"RMSE\"] < best_val_rmse:\n",
    "            best_val_rmse = m_val[\"RMSE\"]\n",
    "            best_params = params\n",
    "\n",
    "    gb_best = GradientBoostingRegressor(\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        random_state=0,\n",
    "    )\n",
    "    gb_best.fit(X_trainval, y_trainval)\n",
    "    y_test_gb = gb_best.predict(X_test)\n",
    "\n",
    "    results[\"gb\"] = regression_metrics(y_test, y_test_gb)\n",
    "    strategies[\"gb\"] = evaluate_strategy(y_test, y_test_gb)\n",
    "    preds[\"gb\"] = y_test_gb\n",
    "\n",
    "    return {\n",
    "        \"metrics\": results,\n",
    "        \"strategies\": strategies,\n",
    "        \"predictions\": preds,\n",
    "        \"ridge_model\": ridge_best,\n",
    "        \"gb_model\": gb_best,\n",
    "        \"best_ridge_alpha\": best_alpha,\n",
    "        \"best_gb_params\": best_params,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_classification_models(X_train, y_class_train, X_val, y_class_val, X_test, y_class_test):\n",
    "    \"\"\"Fit majority, Logistic Regression, and RF; return metrics, strategy stats, predictions.\"\"\"\n",
    "\n",
    "    class_results = {}\n",
    "    strategy_results = {}\n",
    "    preds = {}\n",
    "\n",
    "    # Majority baseline\n",
    "    majority_class = int(np.round(np.mean(y_class_train)))\n",
    "    y_val_major = np.full_like(y_class_val, majority_class)\n",
    "    y_test_major = np.full_like(y_class_test, majority_class)\n",
    "\n",
    "    class_results[\"majority\"] = classification_metrics(y_class_test, y_test_major)\n",
    "    strategy_results[\"majority\"] = evaluate_strategy(y_class_test, y_test_major)\n",
    "    preds[\"majority\"] = y_test_major\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(max_iter=1000)),\n",
    "    ])\n",
    "    log_clf.fit(X_train, y_class_train)\n",
    "    y_val_log = log_clf.predict(X_val)\n",
    "    y_test_log = log_clf.predict(X_test)\n",
    "\n",
    "    class_results[\"logistic\"] = classification_metrics(y_class_test, y_test_log)\n",
    "    strategy_results[\"logistic\"] = evaluate_strategy(y_class_test, y_test_log)\n",
    "    preds[\"logistic\"] = y_test_log\n",
    "\n",
    "    # Random Forest with small grid\n",
    "    rf_param_grid = [\n",
    "        {\"n_estimators\": 200, \"max_depth\": 3},\n",
    "        {\"n_estimators\": 300, \"max_depth\": 3},\n",
    "        {\"n_estimators\": 300, \"max_depth\": 4},\n",
    "    ]\n",
    "\n",
    "    best_rf = None\n",
    "    best_rf_params = None\n",
    "    best_val_acc = -np.inf\n",
    "\n",
    "    for params in rf_param_grid:\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            random_state=0,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        rf.fit(X_train, y_class_train)\n",
    "        y_val_rf = rf.predict(X_val)\n",
    "        m_val = classification_metrics(y_class_val, y_val_rf)\n",
    "        if m_val[\"accuracy\"] > best_val_acc:\n",
    "            best_val_acc = m_val[\"accuracy\"]\n",
    "            best_rf = rf\n",
    "            best_rf_params = params\n",
    "\n",
    "    y_test_rf = best_rf.predict(X_test)\n",
    "\n",
    "    class_results[\"rf\"] = classification_metrics(y_class_test, y_test_rf)\n",
    "    strategy_results[\"rf\"] = evaluate_strategy(y_class_test, y_test_rf)\n",
    "    preds[\"rf\"] = y_test_rf\n",
    "\n",
    "    return {\n",
    "        \"metrics\": class_results,\n",
    "        \"strategies\": strategy_results,\n",
    "        \"predictions\": preds,\n",
    "        \"rf_model\": best_rf,\n",
    "        \"rf_params\": best_rf_params,\n",
    "        \"majority_class\": majority_class,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d3bfd-2dc9-4d54-ab6b-31e4c22edd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-mac)",
   "language": "python",
   "name": "tf-mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
