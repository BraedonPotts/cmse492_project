{
 "cells": [
  {
   "cell_type": "raw",
   "id": "00278f8a-76b6-4f38-acd3-6bb3af21ed4d",
   "metadata": {},
   "source": [
    "% ---- Title & author (rubric 1) ----\n",
    "\\section*{Title and Author Information}\n",
    "\\textbf{Project Title:} Short-Horizon Return Prediction for SMCI with Supervised Learning\\\\\n",
    "\\textbf{Name:} Braedon Potts \\qquad\n",
    "\\textbf{Email:} your_msu_email@msu.edu \\qquad\n",
    "\\textbf{GitHub:} \\url{https://github.com/BraedonPotts/cmse492_project}\\\\[4pt]\n",
    "\\textbf{Date:} \\today\n",
    "\n",
    "% ---- Abstract (rubric 2) ----\n",
    "\\section*{Abstract}\n",
    "This project tests whether short-horizon signals exist in daily OHLCV for \\textbf{SMCI}. We cast next-day \\emph{log return} prediction as a supervised \\emph{regression} task. A naive random-walk forecast ($\\hat r_{t+1}=0$) serves as baseline. Our initial model is \\emph{Ridge regression} using past-only features: recent mean returns (1/5/21-day), rolling volatility (21-day std), and log-volume change. We plan to compare against a gradient-boosting model; a small LSTM may be explored if time permits. Validation uses expanding, time-aware splits with MAE, RMSE, and $R^2$. To link predictions to decisions, we evaluate a simple rule (long if $\\hat r_{t+1}>0$) and report hit rate, annualized Sharpe, and max drawdown. Preliminary EDA reveals regime shifts in trend and volatility since 2017. The contribution is an end-to-end, leakage-aware, reproducible pipeline.\n",
    "\n",
    "% ---- Background & Motivation (rubric 3) ----\n",
    "\\section{Background and Motivation}\n",
    "\\textbf{Problem.} Can past OHLCV forecast the sign/magnitude of SMCI's next-day return?\\\\\n",
    "\\textbf{Importance.} Even small gains can aid timing and risk; academically, this demonstrates correct time-series validation and leakage control.\\\\\n",
    "\\textbf{Existing approaches \\& limits.} Many demos leak future info, overfit with high-capacity models, or use iid CV instead of time-aware splits.\\\\\n",
    "\\textbf{How ML helps.} Regularized linear models and tree ensembles capture trends/interactions while remaining interpretable.\\\\\n",
    "\\textbf{Contribution.} Clear baselines, careful validation, and transparent reporting.\n",
    "\n",
    "% ---- Data Description (rubric 4) ----\n",
    "\\section{Data Description}\n",
    "\\textbf{Source \\& provenance.} Yahoo Finance via \\texttt{yfinance} (pulled on \\today). Daily OHLCV for SMCI, 2017--2025, adjusted for splits/dividends.\\\\\n",
    "\\textbf{Size \\& schema.} \\texttt{Date, Open, High, Low, Close, Volume}.\\\\\n",
    "\\textbf{Quality assessment.} Check NaNs (corporate actions), dtype consistency, duplicates; weekends/holidays are absent by design.\\\\\n",
    "\\textbf{Planned preprocessing.} Parse/sort dates; compute rolling features with warm-up; drop rows without sufficient lookback.\n",
    "\n",
    "\\begin{figure}[h]\n",
    "  \\centering\n",
    "  \\includegraphics[width=0.92\\linewidth]{figures/smci_close_ma.png}\n",
    "  \\caption{SMCI Close with 50/200-day moving averages (trend regimes).}\n",
    "\\end{figure}\n",
    "\n",
    "\\begin{figure}[h]\n",
    "  \\centering\n",
    "  \\includegraphics[width=0.92\\linewidth]{figures/smci_returns_hist.png}\n",
    "  \\caption{Histogram of daily returns (location/scale, heavy tails).}\n",
    "\\end{figure}\n",
    "\n",
    "% ---- Proposed Methodology (rubric 5) ----\n",
    "\\section{Proposed Methodology}\n",
    "\\textbf{Target.} $y_{t+1}=\\log(\\text{Close}_{t+1})-\\log(\\text{Close}_{t})$.\\\\\n",
    "\\textbf{Features (past-only).} $r_t$; 5/21-day mean returns; 21-day rolling std; $\\Delta \\log(\\text{Volume})$; (optional) RSI(14), Bollinger \\%B, MA-cross indicators.\\\\\n",
    "\\textbf{Models (increasing complexity).}\n",
    "\\begin{enumerate}\n",
    "  \\item Naive baseline: $\\hat y_{t+1}=0$\n",
    "  \\item Ridge regression (L2)\n",
    "  \\item Gradient Boosting (tree ensembles)\n",
    "  \\item \\textit{Stretch:} small LSTM\n",
    "\\end{enumerate}\n",
    "\\textbf{Validation \\& leakage control.} Expanding walk-forward; features only use info available by time $t$; hyperparameters chosen on validation folds.\n",
    "\n",
    "% ---- Evaluation Framework (rubric 6) ----\n",
    "\\section{Evaluation Framework}\n",
    "\\textbf{Metrics.} MAE, RMSE, $R^2$; plus decision metrics for ``long-if-$\\hat y_{t+1}>0$'': hit rate, annualized Sharpe ($\\times\\sqrt{252}$), max drawdown.\\\\\n",
    "\\textbf{Splits.} 60\\% train, 20\\% validation, 20\\% test; also report rolling walk-forward results.\\\\\n",
    "\\textbf{Baselines.} Naive forecast and constant-mean model.\n",
    "\n",
    "% ---- Timeline & Milestones (rubric 7) ----\n",
    "\\section{Timeline and Milestones}\n",
    "\\textbf{Plan.} Now--Nov 10: intake/cleaning, EDA figures. Nov 11--Nov 24: baselines, Ridge, Gradient Boosting, walk-forward. Nov 25--Dec 4: polish plots/tables, write-up. Dec 8: final report/code.\\\\\n",
    "\\textbf{Gantt Figure.} (If you export a PNG named \\texttt{gantt.png} next to your notebook, include it:)\n",
    "\\begin{figure}[h]\n",
    "  \\centering\n",
    "  \\includegraphics[width=0.95\\linewidth]{figures/gantt.png}\n",
    "  \\caption{Gantt chart of tasks, dependencies, and buffers.}\n",
    "\\end{figure}\n",
    "\n",
    "% ---- References ----\n",
    "\\section*{References}\n",
    "Hastie, Tibshirani, Friedman. \\emph{The Elements of Statistical Learning}.\\\\\n",
    "Friedman. ``Greedy Function Approximation: A Gradient Boosting Machine.''\\\\\n",
    "Yahoo Finance / \\texttt{yfinance} (data acquisition).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708bb18-20b5-434d-bbf3-a5d6240cc908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-mac)",
   "language": "python",
   "name": "tf-mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
